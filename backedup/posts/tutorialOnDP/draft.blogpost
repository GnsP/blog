title : A Tutorial On Dynamic Programming (Top Down Approach)
abstract : Dynamic Programming (DP) is an algorithmic technique generally used in solving optimization problems. Dynamic Programming is an important and quite difficult technique to master, but it's highly useful as DP can reduce problems of exponential brute-force time complexity to polynomial complexity.
categories : Coding

----------------------------------------------------------------------

Now that a lot of people have asked me for some good resources on DP and I could find only a few good resources to give the beginners a real boost, I decided to write this basic DP tutorial here. But before we go deep into it, I want to make it clear that the only way to master DP is a lot of practice. The more you solve, the better you get.

DP is an ART. It’s a way of thinking. It’s more like learning to see the same thing from a different angle. It takes some time to get used to, that’s why practicing without getting disheartened is the key to mastering DP.

Prerequisites are
  1. *iteration over multidimensional arrays*
  2. *recursion*
  3. *basic knowledge of mathematical notations*

Let’s start with some guidelines on what to think and what not to think and when to use DP. Let’s start with training the mind for seeing things from a different angle.

1. Whenever you see that a problem is minimizing or maximizing a variable by choosing some values in some order over a sequence of values, close your eyes mates and go for DP straight away. In other words, if you are to make a decision about which value in an array should you choose so that the final result after choosing all values in that array will be minimum or maximum, then it’s a DP problem.

2. When you solve a DP problem, the trick is “**Don’t think too much, because the solution is always hidden in the problem**”. Believe in this zen principle and you’ll be good to go and DP will be a piece of cake for you. Most beginners make this mistake of thinking too much, only because they thought the problem was difficult and hence only a complex solution will solve it. But in fact DP is much simpler than their imaginations, so evidently they fail to see the DP solution even if it flutters under their noses.

3. **Before you start coding, formulate the problem (*not the solution*) mathematically on a piece of paper**. Because like I said, the problem is itself the solution.


#### PROBLEM 1

I am to count from 1 to N. But I follow a special rule of counting, I can count either 2*x or 3*x or x+1 after I count x. I always start counting from 1. Now what is the minimum number of steps required to count to N.

Here is the example of this counting : If I want to count till 7, I can count like the following:

    1 2 3 4 5 6 7
    1 2 4 5 6 7
    1 2 3 6 7
    1 3 6 7
    1 2 6 7

In this case the minimum number of steps is 4.

**Now let’s analyze this problem**. Here we are asked to choose which number to count after x, such that we will reach N in minimum number of steps. Notice that, we are presented with a choice at a point and we have to make the choice in such a way that the next of our choices will give us the optimal result. So, this is a DP problem.

You might be tempted to think that the fastest way to reach N would be to count x*3 after x whenever possible. If x*3 > N, then try to count x*2 and if x*2 > N, then simply keep counting x+1. That’s the greedy way to solve this problem. And this greedy algorithm does not always work. For example if I am to count till 8, the greedy way will be to count like 1 3 6 7 8 (5 steps). But the optimal way would be 1 2 4 8 (4 steps). Another example, count till 13 :  greedy way 1 3 9 10 11 12 13 (7 steps), optimal way 1 3 6 12 13 (5 steps).

Now that we have established greedy algorithm won’t work here, let’s analyze why it does not work. It does not work, because we have assumed that taking x*3 and x*2 and x+1 in the preferential order will solve the problem. We have not considered what the next choices can be before making the current choice. We have not considered that if we take x*3 after x, then will it be optimal ? Or it would be more optimal to take x*2 and then x*2*2 and so on.

Now let’s start solving it.

*Rule-1 :  Don’t think much. Rule-2 : The solution is in the problem. Rule-3 : Formulate the problem first.*

**Formulating the problem** : Let’s see what the problem asks us to do in a mathematical manner.

Let `f(x) = minimum number of steps required to count to x.`
Evidently `f(1) = 1`.
And `f(x) = min( f(x-1) , f(x/2) , f(x/3) ) + 1` (means, if we have already counted till x-1 or x/2 or x/3, then we can reach x in just one step. We just have to find out whether it's faster to reach x-1 or x/2 or x/3. If x-1 is faster to reach than x/2 and x/3, then counting to x-1 and the counting x will definitely take less steps than counting to x/2 then x, or counting to x/3 then x.)

if `x%2 != 0`, we do not consider `f(x/2)` in the above expression, if `x%3 != 0` then we do not consider `f(x/3)` in the above expression. Because if `x%2 != 0`, then `x/2` would not be an integer and `f(x)` is defined only for integers. Same for `f(x/3)`.

So, now we have represented the problem as a mathematical function, whose value we need to find. Now all we need to do is the find an efficient way of calculating f(N), which is our solution.

As we can see, the function `f` is a recursive function. So, we can simply implement it as a recursion in our language of choice and it should work correctly. But pure recursion will be slow when N is large.

But, so far, you can see that, we have thought nothing complex, nothing beyond the things mentioned in the problem itself, and we have a solution. That too a recursive solution. And as you must be knowing, every DP has its recursive definition. We just found the recurrence relation for our DP.

Let’s see, why pure recursion is slow :  I want to find `f(7)`.

    f(7) = f(6) + 1    [as 7/2 and 7/3 are not integers]
    f(6) = min ( f(5), f(3), f(2) ) + 1
    f(5) = f(4) + 1
    f(4) = min ( f(3) , f(2) ) + 1
    f(3) = min( f(2), f(1) ) + 1
    f(2) = f(1) + 1
    f(1) = 1

As you can see, in pure recursion, we will have to calculate `f(3)` and `f(2)` more than once. First during `f(6)` we call `f(5)` and it calls `f(4)` which calls `f(3)` and `f(2)`. When `f(4)` and `f(5)` have returned and we are back in `f(6)`, we call `f(3)` and `f(2)` again.  Now that's a waste of time and resources, because the value of `f(2)` and `f(3)` do not change between the calls from `f(4)` and `f(6)`.

Hence, pure recursion is slow. But what if we calculate the values of `f(x)` when needed for the first time and store it in an array and the next time it’s needed we simply look up the array and return the value without really calculating it all over again ?

That would be a much faster way to calculate `f(N)`. And this way is known as **memorization aka top-down DP**. Let’s now see, how the above idea can be implemented in programming. (in C++ like pseudo code).

    int memory[N+1];    // global array, all values initialized to 0
    memory[1] = 1;     // because f(1) = 1
    int f( int x ){
         /* if f(x) is calculated and stored in memory, i.e the value in memory[x]
            is not the default value 0, then just return it without calculation */
          if ( memory[x] != 0 ) return memory[x];
          /* otherwise calculate it recursively */
          int result = INFINITY;
          if ( x%2 == 0 )
              result = min (result, f(x/2) );
          if ( x%3 == 0 )
              result = min (result, f(x/3) );
          result = min (result, f(x-1) );
          result = result + 1;
          /* now store the result in the array for future use and return */
          memory[x] = result;
         return result;
    }

Makes sense ? If not, pause a bit here and read the pseudo code above. Try to imagine how it works during subsequent calls.

Just being able to solve a problem using top-down DP aka memorization is enough in most of the cases. But, when the dataset if too large, the number of recursive calls might result in a function stack overflow error. Normally reported as a case of SIGSSEV or more commonly segmentation fault. If you use Python, in such cases you’ll get a call stack overflow error. Hence it’s important to learn how to solve the DP problems without recursion. That is called “**Bottom-up DP**” . 

*The bottom-up approach requires a little bit more thinking, but always results in more memory efficient, faster and often less lines of code*. The idea is, if we are calculating each value only once and then reusing that value in subsequent calls, why not calculate them bottom-up rather than recursively calling them.


